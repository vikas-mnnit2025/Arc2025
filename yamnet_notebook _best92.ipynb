{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af710b04-e459-4e90-8c07-aa5da7fb5e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vishal Kumar Patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import resampy\n",
    "import librosa\n",
    "import spec_augment\n",
    "import yamnet as yamnet_model\n",
    "import params as yamnet_params\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import yamnet as yamnet_model\n",
    "import params as yamnet_params\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from audiomentations import Compose, AddBackgroundNoise, TimeStretch, PitchShift, Shift, AddGaussianNoise\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd3bb9f-247e-4333-b22a-d07d2c87737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_finetunable_yamnet():\n",
    "    params = yamnet_params.Params()\n",
    "    model = yamnet_model.yamnet_frames_model(params)\n",
    "    model.load_weights('yamnet.h5')  # download: https://storage.googleapis.com/audioset/yamnet.h5\n",
    "\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78565ab-9f75-4b6e-996f-cbf36419d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def augment_audio(audio, sr):\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         audio = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=np.random.randint(-2, 3))\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         audio = librosa.effects.time_stretch(y=audio, rate=np.random.uniform(0.8, 1.2))\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         noise = 0.005 * np.random.randn(len(audio))\n",
    "#         audio = audio + noise\n",
    "#     return np.clip(audio, -1.0, 1.0)\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, Gain\n",
    "\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "    Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "    Gain(min_gain_db=-6, max_gain_db=6, p=0.5)\n",
    "])\n",
    "\n",
    "# from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, Gain, ClippingDistortion, PolarityInversion\n",
    "\n",
    "# augment = Compose([\n",
    "#     AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "#     TimeStretch(min_rate=0.85, max_rate=1.15, p=0.5),\n",
    "#     PitchShift(min_semitones=-3, max_semitones=3, p=0.5),\n",
    "#     Shift(min_shift=-0.2, max_shift=0.2, p=0.5),\n",
    "#     Gain(min_gain_db=-6, max_gain_db=6, p=0.5),\n",
    "#     ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=30, p=0.4),  # Random distortion\n",
    "#     PolarityInversion(p=0.3),  # Flip signal polarity\n",
    "# ])\n",
    "# Function to apply SpecAugment\n",
    "# def apply_specaugment(mel_spec):\n",
    "#     mel_spec = np.expand_dims(mel_spec, axis=0)  # Add batch dimension\n",
    "#     mel_spec = tf.convert_to_tensor(mel_spec, dtype=tf.float32)\n",
    "\n",
    "#     # Apply SpecAugment\n",
    "#     augmented_mel_spec = spec_augment.augment(mel_spec)\n",
    "\n",
    "#     return augmented_mel_spec.numpy().squeeze()  # Remove batch dimension\n",
    "\n",
    "def apply_specaugment(mel_spec, time_mask_param=10, freq_mask_param=8):\n",
    "    mel = mel_spec.copy()\n",
    "    num_mel_channels, num_time_steps = mel.shape\n",
    "\n",
    "    # Time mask\n",
    "    t = np.random.randint(0, time_mask_param)\n",
    "    t0 = np.random.randint(0, max(1, num_time_steps - t))\n",
    "    mel[:, t0:t0 + t] = 0\n",
    "\n",
    "    # Frequency mask\n",
    "    f = np.random.randint(0, freq_mask_param)\n",
    "    f0 = np.random.randint(0, max(1, num_mel_channels - f))\n",
    "    mel[f0:f0 + f, :] = 0\n",
    "\n",
    "    return mel\n",
    "\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    audio = augment(samples=audio, sample_rate=sr)\n",
    "    return np.clip(audio, -1.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ec7184-e93f-4fcb-b9d8-efba53a562b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features_finetuned(yamnet, audio_path, sample_rate=16000):\n",
    "#     # try:\n",
    "#         y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "#         y = augment_audio(y, sr)  # <—— AUGMENTED HERE\n",
    "\n",
    "#         waveform = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "#         waveform = tf.reshape(waveform, [-1])\n",
    "\n",
    "#         _, embeddings, _ = yamnet(waveform)\n",
    "#         avg_embedding = tf.reduce_mean(embeddings, axis=0).numpy()  # (1024,)\n",
    "\n",
    "#         mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)\n",
    "#         mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "#         mel_spec_flat = np.mean(mel_spec_db, axis=1)  # (40,)\n",
    "\n",
    "#         return np.concatenate([avg_embedding, mel_spec_flat])  # (1064,)\n",
    "def extract_features_finetuned(yamnet, audio_path, sample_rate=16000, use_specaugment=True):\n",
    "    y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "    y = augment_audio(y, sr)  # Apply other augmentations like time stretch, pitch shift\n",
    "\n",
    "    waveform = tf.convert_to_tensor(y, dtype=tf.float32)\n",
    "    waveform = tf.reshape(waveform, [-1])\n",
    "\n",
    "    # Get YAMNet embeddings\n",
    "    _, embeddings, _ = yamnet(waveform)\n",
    "    avg_embedding = tf.reduce_mean(embeddings, axis=0).numpy()  # (1024,)\n",
    "\n",
    "    # Create Mel-spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    # Apply SpecAugment during training (not for validation/test)\n",
    "    if use_specaugment:\n",
    "        mel_spec_db = apply_specaugment(mel_spec_db)\n",
    "\n",
    "    mel_spec_flat = np.mean(mel_spec_db, axis=1)  # (40,)\n",
    "    \n",
    "    return np.concatenate([avg_embedding, mel_spec_flat])  # Concatenate YAMNet embeddings with Mel-spectrogram features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f00f1a-5c3e-48ba-841c-9f47b8c9a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_folder(base_path):\n",
    "    X, y = [], []\n",
    "    yamnet = load_finetunable_yamnet()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels = sorted(os.listdir(base_path))  # e.g., ['child_danger', 'normal', 'woman_danger']\n",
    "    label_encoder.fit(all_labels)\n",
    "\n",
    "    for label in tqdm(all_labels, desc=\"Processing folders\"):\n",
    "        folder_path = os.path.join(base_path, label)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                features = extract_features_finetuned(yamnet, file_path)\n",
    "                # features = extract_features_finetuned(yamnet, file_path, augment_audio=True)\n",
    "                if features is not None:\n",
    "                    X.append(features)\n",
    "                    y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = label_encoder.transform(y)\n",
    "    return X, y, label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0effaca-acc4-4f44-81df-567f5584ace2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vishal Kumar Patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Vishal Kumar Patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders:   0%|                                                                        | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "X, y, label_encoder = extract_features_from_folder(r'C:\\Users\\Vishal Kumar Patel\\Desktop\\Yamnetmodelproject\\data\\train')\n",
    "print(\"Feature shape:\", X.shape)\n",
    "print(\"Label shape:\", y.shape)\n",
    "print(\"Classes:\", label_encoder.classes_) \n",
    "np.save(\"X_embeddings_augmented.npy\", X)\n",
    "np.save(\"y_labels_augmented.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070e0c83-fd57-4695-bf47-7efeada7c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load embeddings and labels from saved files\n",
    "X = np.load(\"X_embeddings_augmented.npy\")  # shape: (n_samples, 1024)\n",
    "y = np.load(\"y_labels_augmented.npy\")      # shape: (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37e6889f-d103-4902-82e7-1fcbdad37d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1064</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,221,632</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1064\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m1,221,632\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m1,024\u001b[0m │ bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m257\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply_3 (\u001b[38;5;33mMultiply\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m32,896\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │             \u001b[38;5;34m258\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,256,579</span> (4.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,256,579\u001b[0m (4.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,255,811</span> (4.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,255,811\u001b[0m (4.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, BatchNormalization, Activation, Multiply, Flatten, Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# ----------------- Data Preprocessing -----------------\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_cat = to_categorical(y, num_classes)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Reshape for BiLSTM [samples, time_steps=1, features]\n",
    "X_train = np.expand_dims(X_train, axis=1)\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=np.argmax(y_cat, axis=1))\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# ----------------- Attention Block -----------------\n",
    "def attention_block(inputs):\n",
    "    attention_weights = Dense(1, activation='tanh')(inputs)\n",
    "    attention_weights = Activation('softmax')(attention_weights)\n",
    "    weighted_input = Multiply()([inputs, attention_weights])\n",
    "    context_vector = Lambda(lambda x: K.sum(x, axis=1))(weighted_input)\n",
    "    # context_vector = Lambda(lambda x: K.sum(x, axis=1), output_shape=(inputs.shape[1],))(weighted_input)  \n",
    "    return context_vector\n",
    "\n",
    "# ----------------- Model Definition -----------------\n",
    "input_layer = Input(shape=(1, X.shape[1]))  # Define input shape\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = attention_block(x)\n",
    "x = Flatten()(x) \n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ----------------- Summary -----------------\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Dropout, Layer, Flatten, Multiply, Permute\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "# # One-hot encode labels\n",
    "# num_classes = len(np.unique(y))\n",
    "# y_cat = to_categorical(y, num_classes)\n",
    "\n",
    "# # Train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# # Reshape for BiLSTM [samples, time_steps=1, features]\n",
    "# X_train = np.expand_dims(X_train, axis=1)\n",
    "# X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# # Compute class weights\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=np.argmax(y_cat, axis=1))\n",
    "# class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# # ----------------- Attention Layer -----------------\n",
    "# class Attention(Layer):\n",
    "#     def __init__(self, **kwargs):\n",
    "#         super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], 1),\n",
    "#                                  initializer='normal', trainable=True)\n",
    "#         self.b = self.add_weight(name='att_bias', shape=(input_shape[1], 1),\n",
    "#                                  initializer='zeros', trainable=True)\n",
    "#         super(Attention, self).build(input_shape)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "#         a = tf.keras.backend.softmax(e, axis=1)\n",
    "#         output = x * a\n",
    "#         return tf.keras.backend.sum(output, axis=1)\n",
    "\n",
    "# # ----------------- Model Architecture -----------------\n",
    "# input_layer = Input(shape=(1, 1064))  # Input shape\n",
    "# x = tf.keras.layers.Reshape((1064, 1))(input_layer)  # Reshape for LSTM\n",
    "\n",
    "# x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Attention()(x)\n",
    "\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs=input_layer, outputs=output_layer)\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce63f079-1999-40fb-9465-eee6b852d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishal Kumar Patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py:908: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8210 - loss: 0.4785\n",
      "Epoch 1: val_loss improved from inf to 0.33801, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - accuracy: 0.8213 - loss: 0.4777 - val_accuracy: 0.8659 - val_loss: 0.3380 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8999 - loss: 0.2683\n",
      "Epoch 2: val_loss improved from 0.33801 to 0.30008, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.8999 - loss: 0.2684 - val_accuracy: 0.8841 - val_loss: 0.3001 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9026 - loss: 0.2486\n",
      "Epoch 3: val_loss improved from 0.30008 to 0.22833, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9027 - loss: 0.2485 - val_accuracy: 0.9124 - val_loss: 0.2283 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9028 - loss: 0.2395\n",
      "Epoch 4: val_loss did not improve from 0.22833\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9028 - loss: 0.2394 - val_accuracy: 0.9035 - val_loss: 0.2445 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9150 - loss: 0.2201\n",
      "Epoch 5: val_loss did not improve from 0.22833\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.9150 - loss: 0.2202 - val_accuracy: 0.9024 - val_loss: 0.2365 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9155 - loss: 0.2156\n",
      "Epoch 6: val_loss did not improve from 0.22833\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9155 - loss: 0.2156 - val_accuracy: 0.8875 - val_loss: 0.2820 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9218 - loss: 0.2009\n",
      "Epoch 7: val_loss improved from 0.22833 to 0.22126, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9219 - loss: 0.2008 - val_accuracy: 0.9174 - val_loss: 0.2213 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9297 - loss: 0.1876\n",
      "Epoch 8: val_loss improved from 0.22126 to 0.19626, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9297 - loss: 0.1876 - val_accuracy: 0.9224 - val_loss: 0.1963 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9341 - loss: 0.1778\n",
      "Epoch 9: val_loss did not improve from 0.19626\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9341 - loss: 0.1778 - val_accuracy: 0.9163 - val_loss: 0.2122 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9258 - loss: 0.1907\n",
      "Epoch 10: val_loss improved from 0.19626 to 0.19007, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9258 - loss: 0.1906 - val_accuracy: 0.9257 - val_loss: 0.1901 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9277 - loss: 0.1830\n",
      "Epoch 11: val_loss did not improve from 0.19007\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9277 - loss: 0.1829 - val_accuracy: 0.8503 - val_loss: 0.3161 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9304 - loss: 0.1772\n",
      "Epoch 12: val_loss did not improve from 0.19007\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9304 - loss: 0.1772 - val_accuracy: 0.9174 - val_loss: 0.2195 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9336 - loss: 0.1628\n",
      "Epoch 13: val_loss improved from 0.19007 to 0.18641, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.9336 - loss: 0.1629 - val_accuracy: 0.9224 - val_loss: 0.1864 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9433 - loss: 0.1506\n",
      "Epoch 14: val_loss did not improve from 0.18641\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.9432 - loss: 0.1507 - val_accuracy: 0.9180 - val_loss: 0.1958 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9376 - loss: 0.1554\n",
      "Epoch 15: val_loss did not improve from 0.18641\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9376 - loss: 0.1555 - val_accuracy: 0.9180 - val_loss: 0.2006 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9369 - loss: 0.1658\n",
      "Epoch 16: val_loss improved from 0.18641 to 0.18535, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9368 - loss: 0.1658 - val_accuracy: 0.9241 - val_loss: 0.1854 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9324 - loss: 0.1676\n",
      "Epoch 17: val_loss did not improve from 0.18535\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9324 - loss: 0.1676 - val_accuracy: 0.9174 - val_loss: 0.2187 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9341 - loss: 0.1641\n",
      "Epoch 18: val_loss did not improve from 0.18535\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9341 - loss: 0.1641 - val_accuracy: 0.9180 - val_loss: 0.1984 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9354 - loss: 0.1652\n",
      "Epoch 19: val_loss did not improve from 0.18535\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9355 - loss: 0.1651 - val_accuracy: 0.9191 - val_loss: 0.1956 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9353 - loss: 0.1523\n",
      "Epoch 20: val_loss improved from 0.18535 to 0.17175, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9353 - loss: 0.1523 - val_accuracy: 0.9290 - val_loss: 0.1717 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9497 - loss: 0.1293\n",
      "Epoch 21: val_loss did not improve from 0.17175\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9496 - loss: 0.1294 - val_accuracy: 0.9235 - val_loss: 0.1930 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9443 - loss: 0.1374\n",
      "Epoch 22: val_loss did not improve from 0.17175\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9443 - loss: 0.1374 - val_accuracy: 0.9346 - val_loss: 0.1819 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9437 - loss: 0.1522\n",
      "Epoch 23: val_loss did not improve from 0.17175\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9436 - loss: 0.1521 - val_accuracy: 0.9279 - val_loss: 0.1797 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9509 - loss: 0.1321\n",
      "Epoch 24: val_loss did not improve from 0.17175\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9509 - loss: 0.1321 - val_accuracy: 0.9302 - val_loss: 0.1722 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9501 - loss: 0.1325\n",
      "Epoch 25: val_loss did not improve from 0.17175\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9501 - loss: 0.1325 - val_accuracy: 0.9279 - val_loss: 0.1769 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9561 - loss: 0.1202\n",
      "Epoch 26: val_loss improved from 0.17175 to 0.17160, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9560 - loss: 0.1203 - val_accuracy: 0.9340 - val_loss: 0.1716 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9425 - loss: 0.1317\n",
      "Epoch 27: val_loss improved from 0.17160 to 0.16883, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9426 - loss: 0.1317 - val_accuracy: 0.9285 - val_loss: 0.1688 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9418 - loss: 0.1423\n",
      "Epoch 28: val_loss did not improve from 0.16883\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9418 - loss: 0.1422 - val_accuracy: 0.9257 - val_loss: 0.1882 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9485 - loss: 0.1284\n",
      "Epoch 29: val_loss did not improve from 0.16883\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9485 - loss: 0.1284 - val_accuracy: 0.9224 - val_loss: 0.1930 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9558 - loss: 0.1161\n",
      "Epoch 30: val_loss did not improve from 0.16883\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9557 - loss: 0.1161 - val_accuracy: 0.9290 - val_loss: 0.1823 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9494 - loss: 0.1285\n",
      "Epoch 31: val_loss did not improve from 0.16883\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9494 - loss: 0.1285 - val_accuracy: 0.9329 - val_loss: 0.1736 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9562 - loss: 0.1155\n",
      "Epoch 32: val_loss did not improve from 0.16883\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9561 - loss: 0.1156 - val_accuracy: 0.9307 - val_loss: 0.1714 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9500 - loss: 0.1259\n",
      "Epoch 33: val_loss did not improve from 0.16883\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9500 - loss: 0.1258 - val_accuracy: 0.9302 - val_loss: 0.1706 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9619 - loss: 0.1067\n",
      "Epoch 34: val_loss improved from 0.16883 to 0.16864, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9618 - loss: 0.1068 - val_accuracy: 0.9307 - val_loss: 0.1686 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9557 - loss: 0.1145\n",
      "Epoch 35: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9557 - loss: 0.1145 - val_accuracy: 0.9302 - val_loss: 0.1712 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.1132\n",
      "Epoch 36: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9567 - loss: 0.1131 - val_accuracy: 0.9296 - val_loss: 0.1714 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9578 - loss: 0.1084\n",
      "Epoch 37: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9578 - loss: 0.1084 - val_accuracy: 0.9318 - val_loss: 0.1724 - learning_rate: 3.1250e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9543 - loss: 0.1202\n",
      "Epoch 38: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9542 - loss: 0.1203 - val_accuracy: 0.9324 - val_loss: 0.1725 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9532 - loss: 0.1146\n",
      "Epoch 39: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9533 - loss: 0.1146 - val_accuracy: 0.9318 - val_loss: 0.1720 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m224/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9562 - loss: 0.1037\n",
      "Epoch 40: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9561 - loss: 0.1038 - val_accuracy: 0.9313 - val_loss: 0.1708 - learning_rate: 1.5625e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9543 - loss: 0.1156\n",
      "Epoch 41: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9542 - loss: 0.1157 - val_accuracy: 0.9324 - val_loss: 0.1716 - learning_rate: 7.8125e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9548 - loss: 0.1150\n",
      "Epoch 42: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9548 - loss: 0.1150 - val_accuracy: 0.9313 - val_loss: 0.1716 - learning_rate: 7.8125e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9562 - loss: 0.1181\n",
      "Epoch 43: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9561 - loss: 0.1181 - val_accuracy: 0.9302 - val_loss: 0.1710 - learning_rate: 7.8125e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m225/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9567 - loss: 0.1137\n",
      "Epoch 44: val_loss did not improve from 0.16864\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9567 - loss: 0.1137 - val_accuracy: 0.9302 - val_loss: 0.1709 - learning_rate: 3.9063e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2215adef680>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=50,\n",
    "#     batch_size=64,\n",
    "#     class_weight=class_weights_dict,\n",
    "#     callbacks=[early_stop],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_split=0.2,\n",
    "#     epochs=50,\n",
    "#     batch_size=64,\n",
    "#     class_weight=class_weights_dict,\n",
    "#     callbacks=[reduce_lr, early_stop],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# ----------------- Callbacks -----------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# ----------------- Train Model -----------------\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bfed68e-8894-4d71-8824-3201ab54e36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9337 - loss: 0.1638\n",
      "✅ Test Accuracy: 93.07%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"✅ Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9a9ec4-395d-4d18-86dc-74575e71a23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/57\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 418ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishal Kumar Patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\ops\\nn.py:908: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       904\n",
      "           1       0.93      0.93      0.93       900\n",
      "\n",
      "    accuracy                           0.93      1804\n",
      "   macro avg       0.93      0.93      0.93      1804\n",
      "weighted avg       0.93      0.93      0.93      1804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model.predict(X_test)\n",
    "predicted_train = model.predict(X_train)\n",
    "predicted_class = []\n",
    "for i in range(len(predicted_train)):\n",
    "  predicted_class.append(np.argmax(predicted_train[i]))\n",
    "predicted_class_index = []\n",
    "for i in range(len(predicted_test)):\n",
    "  predicted_class_index.append(np.argmax(predicted_test[i]))\n",
    "rounded_test = np.argmax(y_test,axis=1)\n",
    "rounded_train = np.argmax(y_train,axis=1)\n",
    "\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(rounded_train, predicted_class)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(rounded_test, predicted_class_index)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(rounded_test, predicted_class_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05875e2-3dc2-4583-902c-b6677b6f4567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "woman_danger       0.93      0.93      0.93       904\n",
      "      normal       0.93      0.93      0.93       900\n",
      "\n",
      "    accuracy                           0.93      1804\n",
      "   macro avg       0.93      0.93      0.93      1804\n",
      "weighted avg       0.93      0.93      0.93      1804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=['woman_danger', 'normal']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83c058e8-4452-4c06-bc5f-ac2a1abdce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94adfaef-c8b5-4751-a043-c077f0b4033d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
